{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Yt8sJlJ94G",
        "outputId": "a44635f8-e883-4376-91e3-bfc00e3ffd65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "print(data.columns) #dataframe from pd so cant use keys\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.isnull()) #shows False if not null, and True if null i.e. missing\n",
        "print(data.isnull().sum()) #sums all the True across columns: Cabin most null, then age, embarked (but only 2)"
      ],
      "metadata": {
        "id": "hKgDG0bv8LKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b947937-add6-40cf-8bea-5272247cf671",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     PassengerId  Survived  Pclass   Name    Sex    Age  SibSp  Parch  Ticket  \\\n",
            "0          False     False   False  False  False  False  False  False   False   \n",
            "1          False     False   False  False  False  False  False  False   False   \n",
            "2          False     False   False  False  False  False  False  False   False   \n",
            "3          False     False   False  False  False  False  False  False   False   \n",
            "4          False     False   False  False  False  False  False  False   False   \n",
            "..           ...       ...     ...    ...    ...    ...    ...    ...     ...   \n",
            "886        False     False   False  False  False  False  False  False   False   \n",
            "887        False     False   False  False  False  False  False  False   False   \n",
            "888        False     False   False  False  False   True  False  False   False   \n",
            "889        False     False   False  False  False  False  False  False   False   \n",
            "890        False     False   False  False  False  False  False  False   False   \n",
            "\n",
            "      Fare  Cabin  Embarked  \n",
            "0    False   True     False  \n",
            "1    False  False     False  \n",
            "2    False   True     False  \n",
            "3    False  False     False  \n",
            "4    False   True     False  \n",
            "..     ...    ...       ...  \n",
            "886  False   True     False  \n",
            "887  False  False     False  \n",
            "888  False   True     False  \n",
            "889  False  False     False  \n",
            "890  False   True     False  \n",
            "\n",
            "[891 rows x 12 columns]\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean data: remove cabin too sparse, age replace with median-wont skew the mean preserving distrubtion w.o bias and is robust to outliers\n",
        "data = data.drop (\"Cabin\", axis =1) #axis=1 says column, and \"Cabin\" is its name\n",
        "print(data.columns) #Cabin has been removed from data so getting errors if i run this, should've renamed it to data_noCabin"
      ],
      "metadata": {
        "id": "HxORzIv9KngW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e7e424-94bf-4fef-87b9-644475c57f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Embarked'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].median()) #fillna is replace NaN with () in this case the median of the column data[Age] and replaces that"
      ],
      "metadata": {
        "id": "gLzVHM8DKni8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Embarked only has 2 missing values so let's pick the most common location\n",
        "data[\"Embarked\"] = data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0]) #instead of just picking S we use mode as I don;t know [0] after mode just selects first if multiple"
      ],
      "metadata": {
        "id": "86kp_KHTKnlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes #figure out what strs needed to be encoded numerically: name? sex? ticket? embarked?\n",
        "#sex and embarked are easy to encode, name doesnt matter so can be dropped, ticket is one I'm unsure of\n",
        "print(data['Sex'].unique()) #all sexes were NaN with my mistake luckily recoverable but once again should be using new names!!!!!\n",
        "data['Sex'] = data['Sex'].str.strip().str.lower().map({'male': 0, 'female': 1}) #strip gets rid of spaces if any and str.lower makes all lower case so fits with my map\n",
        "#Error if run again as now they're all numbers so cant do the conversion, really have to start renaming as a habit!!!!!!!!!"
      ],
      "metadata": {
        "id": "nnKt3TfENYBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c0db63-488f-4caf-d802-1c1e6fea47da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['male' 'female']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Sex'][0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-BJotaBQug6",
        "outputId": "e3b50b5f-a524-4336-e1d0-69aaf537839e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: Sex, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embarked_dummies = pd.get_dummies(data[\"Embarked\"], prefix=\"Embarked\") #selects embarked, contains S,Q,C\n",
        "#pd.get_dummies() converts categorical values into binary for every unique in Embarked and creates new columns\n",
        "#prefix=Embarked gives columns a name starting with Embarked then _S or Q or C\n",
        "data = pd.concat([data, embarked_dummies], axis=1) #concatenate/merge new dataframes, axis=1 does it horizontally as we're adding a column\n",
        "data.drop(\"Embarked\", axis=1, inplace=True) #remove Embarked, it's a column. inplace=True means adjust the dataframe itself"
      ],
      "metadata": {
        "id": "ZF1V4IMdQ9p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to numbers\n",
        "data['Embarked_S'] = data['Embarked_S'].astype(int)\n",
        "data['Embarked_Q'] = data['Embarked_Q'].astype(int)\n",
        "data['Embarked_C'] = data['Embarked_C'].astype(int)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsLvwFEUQ-Iv",
        "outputId": "6dac085f-6a7e-4cbe-eedb-d92c168a6c26",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex   Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
            "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
            "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
            "\n",
            "             Ticket     Fare  Embarked_C  Embarked_Q  Embarked_S  \n",
            "0         A/5 21171   7.2500           0           0           1  \n",
            "1          PC 17599  71.2833           1           0           0  \n",
            "2  STON/O2. 3101282   7.9250           0           0           1  \n",
            "3            113803  53.1000           0           0           1  \n",
            "4            373450   8.0500           0           0           1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.drop(\"Name\", axis=1)\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGgjIbdAULEi",
        "outputId": "f6679523-75cb-4555-9b14-dd2b7ae2ba9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
            "       'Ticket', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[\"Ticket\"].nunique()) #681 unique tickets of 890"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3yqyJ4fUWXX",
        "outputId": "208d2c22-adf2-4718-b165-62378de3343b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_nt = data.drop(\"Ticket\", axis = 1)\n",
        "print(data_nt.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxPr7uKehPYn",
        "outputId": "20e797d0-a32b-4358-dde6-9b198aed1926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
            "       'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I want to separate target from features\n",
        "x=data_nt.drop(\"Survived\", axis = 1)\n",
        "y = data_nt[\"Survived\"]\n",
        "\n",
        "#I want to set up training and test before\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 22) #test is 20% and set 1 random thats recurring"
      ],
      "metadata": {
        "id": "u_7Zm4YXhPcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Logistic Regression from scratch-ish\n",
        "import numpy as np\n",
        "def sigmoid(z):\n",
        "    z = np.array(z, dtype=np.float64)\n",
        "    return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n",
        "\n",
        "#This defines the sigmoid function using np.exp, this is also the log-partition function it is the inverse of the log-odds\n",
        "#probability of a binary outcome live or die, say 30% and 70% output is 0-1 (lives on simplex) Probability was historically mean of distrubtion?\n",
        "#odds= p(1)/p(0) output 0-infinte gives multiples\n",
        "#log odds= log (odds) output is Real number (logit function)\n",
        "#Therefore sigmoid is mapping of real number to simplex, and z is linear combination of features wTx+b=z"
      ],
      "metadata": {
        "id": "vyghGu7RjQ-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(n_features): #this defines a function called i_n and takes in 1 arg(n_f) which is expceted to be an integer\n",
        "  weights=np.zeros(n_features) #creates numpy array of features [0,0,..,0] based on int=n_features\n",
        "  bias = 0\n",
        "  return weights, bias #returns 2 values\n",
        "  #represents weight coefficients we will learn"
      ],
      "metadata": {
        "id": "D84rezbXjRBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Maximize likelihood:  train a model (logistic regression) to predict survival, need best parameters (w)\n",
        "#MLE:“Given the parameters w, what’s the probability of observing true label\n",
        "#MLE=P(y|x;w) generally MLE=yh^y * (1-yh)^1-y where y=1 or 0 if 1 MLE=y^h or 1-yh if samples independent, then take product of all passengers (this was just one)\n",
        "#log MLE turns into addition: Sum of all ylogyh + (1-y)log(1-yh)\n",
        "#now -logMLE=binary cross entropy loss, minimize negative is same as maximizing positive so just take -logMLE -Sigma(ylogyh)+(1-y)log(1-yh)\n",
        "#when y=1 then loss is -logyh and y=0 then -log(1-yh)\n",
        "#normalize BCE by doing: 1/n *Sigma ylogyh + (1-y)log(1-yh)"
      ],
      "metadata": {
        "id": "J0bb-bROjRDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We have a curved parameter manifold, each point is a logistic regression model=probability distrubtion\n",
        "#Above manifold have your loss function defined by BCE which gives a scalar field\n",
        "#Jacobian is first derivative gives gradient of loss function w/ steepest ascent, this is a covector field, 1-form. In coordinates partial derivatives of L/partial parameter co\n",
        "#Hessian is 2nd derivative of loss fnx how the slope changes, 0,2 tensor, gives us curvature at each local point and defines a Riemannian metric (not 2form as not antisymmetric)\n",
        "#NOTE: Minimizing BCE is equivalent to minimizing KL Divergence,  both of their 2nd derivatives give Fisher metric\n",
        "#Also have a simplex, with points b/w by KL Divergence, strictly a different manifold than parameter manifold and the fisher metric is pulled back onto parameter"
      ],
      "metadata": {
        "id": "REROywpFuMT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "#THE FIX!"
      ],
      "metadata": {
        "id": "cg-_L6nqvI5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BCE_loss(y_pred, y_true):\n",
        "    eps = 1e-9\n",
        "    y_pred = np.array(y_pred).astype(np.float64)  # force NumPy float array\n",
        "    y_true = np.array(y_true).astype(np.float64)  # force NumPy float array\n",
        "\n",
        "    # Use NumPy clip — not pandas — to avoid log(0) and future warnings, as well as infinite from logs\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "\n",
        "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "zga0EnehuMc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Forward pass\n",
        "def forward(x, weights, bias):\n",
        "  z= np.dot(x, weights) + bias #wTx+b\n",
        "  y_pred= sigmoid(z) #sigmoid(0) gives output of 0.5, as initial predictions\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "rrYQQOlc26ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1L2KDdKS3lz3",
        "outputId": "2b92295c-3a38-42de-833a-dd21e1cb375c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.34783679 -1.57799795 -0.73561236 ...  2.10597115 -0.30610782\n",
            "  -1.64570147]\n",
            " [ 1.42888881  0.81759809 -0.73561236 ... -0.47484031 -0.30610782\n",
            "   0.60764362]\n",
            " [-1.54687826 -0.38019993  1.35941164 ...  2.10597115 -0.30610782\n",
            "  -1.64570147]\n",
            " ...\n",
            " [ 1.42116957 -0.38019993 -0.73561236 ... -0.47484031 -0.30610782\n",
            "   0.60764362]\n",
            " [-1.20337208  0.81759809  1.35941164 ... -0.47484031 -0.30610782\n",
            "   0.60764362]\n",
            " [ 1.70292184  0.81759809  1.35941164 ... -0.47484031  3.26682279\n",
            "  -1.64570147]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = x_train.shape[1] #num of features/columns\n",
        "weights, bias = initialize_weights(n_features)\n",
        "print(weights, bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UGEWtqx3l5p",
        "outputId": "1305e577-0911-48bf-d82c-2e81c93fb00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradients(x_train, y_true, y_pred):\n",
        "    m = x_train.shape[0]\n",
        "    dw = (1 / m) * np.dot(x_train.T, (y_pred - y_true)) #dL/dw shows how each feature contributes to the error\n",
        "    db = (1 / m) * np.sum(y_pred - y_true) #dL/db same for every output, how bias contributes to error\n",
        "    return dw, db\n"
      ],
      "metadata": {
        "id": "QjU2vrYf5rjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Update gradients\n",
        "def update_parameters(weights, bias, dw, db, learning_rate):\n",
        "    weights = weights - learning_rate * dw\n",
        "    bias = bias - learning_rate * db\n",
        "    return weights, bias\n"
      ],
      "metadata": {
        "id": "6Tjr0sp35r6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(x_train, y_train, weights, bias, learning_rate=0.005, num_epochs=5000):\n",
        "    y_train = np.array(y_train).astype(np.float64)  # ensure clean format\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        y_pred = forward(x_train, weights, bias)\n",
        "        loss = BCE_loss(y_pred, y_train)\n",
        "\n",
        "        dw, db = compute_gradients(x_train, y_train, y_pred)\n",
        "        weights, bias = update_parameters(weights, bias, dw, db, learning_rate)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch {i}, Loss: {loss:.6f}\")\n",
        "\n",
        "    return weights, bias\n"
      ],
      "metadata": {
        "id": "ZEgZ6imHYzaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Actually Run and Train:\n",
        "weights, bias = train(x_train, y_train, weights, bias, learning_rate=0.01, num_epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5ub8clFdOnk",
        "outputId": "1eff8091-8abf-4cb0-bbd0-1ef8177dd47e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.693147\n",
            "Epoch 100, Loss: 0.593690\n",
            "Epoch 200, Loss: 0.541586\n",
            "Epoch 300, Loss: 0.510830\n",
            "Epoch 400, Loss: 0.491124\n",
            "Epoch 500, Loss: 0.477765\n",
            "Epoch 600, Loss: 0.468331\n",
            "Epoch 700, Loss: 0.461459\n",
            "Epoch 800, Loss: 0.456331\n",
            "Epoch 900, Loss: 0.452426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4229cb0e",
        "outputId": "395a0fe1-e541-475c-9454-1771464b523b"
      },
      "source": [
        "# Evaluate the model\n",
        "y_pred_test = forward(x_test, weights, bias)>= 0.5  # predicted labels on test set\n",
        "accuracy = np.mean(y_pred_test == y_test)            # compare with true test labels\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.770949720670391\n"
          ]
        }
      ]
    }
  ]
}